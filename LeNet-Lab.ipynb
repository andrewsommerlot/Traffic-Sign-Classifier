{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Traffic Signs\n",
    "\n",
    "The following code builds off the LeNet lab from the Udacity self driving car nano degree, term 1. I have written my own architiecture for a new convolutional neural net following inpiriation from the GoogLeNet paper and source [2]. defined below. \n",
    "I still have a network with a humble number of layers, though I've added something akin to an inception module as described in source [1], and a n extra fully connected layer in the final stages of the network. Additionaly, I added dropout to the weights of the fully connected layers, excluding the logit layer, and l2 regularization penalties on all fully connected layer weights. I tuned all the hyper parameters mannually to get a decent score. \n",
    "___\n",
    "\n",
    "Additinally, I added the preprocessing steps of appending an upside-down rotation to of all labeled data, doubling the number of training examples and divided all values of input data by 255, forcing the range to [0, 1].\n",
    "___\n",
    "\n",
    "Before final testing, I tried the network on a few pictures of signs outside of the training set I found online. They still were of types represented in the training data.\n",
    "___\n",
    "\n",
    "Just for fun, and to illustrate the limitations of supervised classification, I ran the trained model on some \"out-of-sample\" pictures, including silly paint illustrations and a downsampled picture of my face. The point being, even though a classifier may seem incredible when you look at the performance metrics, you still need to be careful to keep it in its \"play-pen\" during use or the model may behave in a dangerous way.\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a visual of my archetecture:\n",
    "![LeNet Architecture](lenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First thing, I imported all the libraries and functions, and used the code from the class material to import the traffic sign data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import copy\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# sklearn data prep functions \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "#============================================================================\n",
    "\n",
    "#============================================================================\n",
    "# load data and define train, valid, and test sets \n",
    "training_file = \"/home/andy/Desktop/udacity-p2/train.p\"\n",
    "validation_file= \"/home/andy/Desktop/udacity-p2/valid.p\"\n",
    "testing_file = \"/home/andy/Desktop/udacity-p2/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "#============================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "I preprocessed the data with a few simple steps:\n",
    "* Combining training and validation sets\n",
    "* Copying the combined set and rotating all images 180 degrees to an upside-down orientation \n",
    "* Appending the original and rotated\n",
    "* Dividing the resulting dataset by 255 to force input range to [0, 1]\n",
    "* Separating the data into 80% of the labeled data into the training set, and 20% into the validation set \n",
    "\n",
    "I repeated the transformitive preprocessing operatinons on the test set\n",
    "\n",
    "Additinally, I selected 9 examples from the original training set, and 9 from the rotated set before dividing by 255 and plotted them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-ad0691871cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# run prep function on training and validation combo data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mX_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_both\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_both\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# split into train and validation again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-ad0691871cc3>\u001b[0m in \u001b[0;36mdata_prep\u001b[0;34m(X, y, vis_num)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mcpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mX_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mX_big\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mX_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_big\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#============================================================================\n",
    "# Data exploration, visualization, and prep\n",
    "# select a few example images from a few classes from train\\\n",
    "def rand_subset(X_train, index = 9):\n",
    "    #selected_classes = []\n",
    "    #for i in range(0, 5):\n",
    "        #selected_classes.append(randint(train[\"labels\"].min(), train[\"labels\"].max()))\n",
    "\n",
    "    # grab a subset of classes\n",
    "    #train_subset = {\"features\": train[\"features\"] for label in selected_classes}\n",
    "\n",
    "    # get a few random selections \n",
    "    selected_index = []\n",
    "    for i in range(0, index):\n",
    "        selected_index.append(randint(0, X_train.shape[0]-1))\n",
    "    \n",
    "    # final subset \n",
    "    train_subset = X_train[selected_index,:,:,:]\n",
    "    \n",
    "    return train_subset\n",
    "#============================================================================\n",
    "\n",
    "#============================================================================\n",
    "# combine for one processing of training\n",
    "X_both = np.vstack([X_validation, X_train])\n",
    "y_both = np.hstack([y_validation, y_train])\n",
    "#============================================================================\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# define the rotation function. rotates to the left 90 degrees*times\n",
    "def rotate(x, times = 0):\n",
    "    for i in range(0, np.shape(x)[0]):\n",
    "        x[i,:,:,0] = np.rot90(x[i,:,:,0], times)\n",
    "        x[i,:,:,1] = np.rot90(x[i,:,:,1], times)\n",
    "        x[i,:,:,2] = np.rot90(x[i,:,:,2], times)\n",
    "    return x\n",
    "#============================================================================\n",
    "\n",
    "#============================================================================\n",
    "# put the data prep steps in a function for easy repeat on test data\n",
    "def data_prep(X, y, vis_num = 3):\n",
    "    # get an upside down version \n",
    "    cpy = copy.deepcopy(X)\n",
    "    X_c = rotate(cpy, 2)\n",
    "    X_big = np.vstack([X_c, X])\n",
    "    X_01 = X_big / 255\n",
    "    \n",
    "    if y is not None:\n",
    "        # double up the labels and \n",
    "        y_01 = np.hstack([y, y])\n",
    "        # shuyffle\n",
    "        X_01, y_01 = shuffle(X_01, y_01)\n",
    "    else:\n",
    "        X_01  = shuffle(X_01)\n",
    "        y_01 = None\n",
    "\n",
    "    # the final has very small values, so wont look like anything look at the rotation\n",
    "    x_sub = rand_subset(X_c)\n",
    "\n",
    "    # the originals\n",
    "    train_subset = rand_subset(X, index = vis_num)\n",
    "    \n",
    "    tplot = []\n",
    "    tplot = np.vstack([train_subset, x_sub])\n",
    "    \n",
    "    return X_01, y_01, tplot\n",
    "#============================================================================\n",
    "  \n",
    "#============================================================================\n",
    "# run prep function on training and validation combo data\n",
    "X_01, y_01, tplot = data_prep(X_both, y_both, vis_num = 9)\n",
    "\n",
    "# split into train and validation again \n",
    "X_train, X_validation, y_train, y_validation= train_test_split(X_01, y_01, test_size= 0.2)\n",
    "\n",
    "# just do the division on the test data\n",
    "#X_test, y_test, plot_test = data_prep(X_test, y_test)\n",
    "X_test_process = X_test / 255\n",
    "#============================================================================\n",
    "\n",
    "#============================================================================\n",
    "# plot seected examples from original and rotated sets\n",
    "plt.figure(figsize=(18, 18))\n",
    "for i, image in  enumerate(tplot):\n",
    "    plt.subplot(6,3,1+i)\n",
    "    plt.imshow(image)\n",
    "#============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Archetecture\n",
    "The model is a combination of the class lab on LeNet, my code, and inspiration from these sources:\n",
    "\n",
    "source [1] https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf \n",
    "\n",
    "\n",
    "source [2] https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/\n",
    "\n",
    "---\n",
    "\n",
    "The archetecture is as follows: \n",
    "\n",
    "* Input   : 32x32x3\n",
    "\n",
    "\n",
    "* Layer  1: \n",
    "\n",
    "    * 3x3x6 filter Convolution\n",
    "\n",
    "    * 2x2x6 filter Max pool\n",
    "    \n",
    "\n",
    "* Layer  2: 5x5x12 filter Convolution\n",
    "\n",
    "\n",
    "* Layer  3: Inception-like module concatonating:\n",
    "    * 1x1x12 filter convolution\n",
    "    \n",
    "    * 1x1x12 filter convolution -> 5x5x12 filter convolution\n",
    "    \n",
    "    * 3x3x12 filter Max pool -> 1x1x12 filter convolution\n",
    "    \n",
    "    * 1x1x12 filter convlution -> 3x3x12 filter convolution\n",
    "    \n",
    "    \n",
    "* Layer  4:\n",
    "    * x7x60 filter convolution\n",
    "\n",
    "    * x2x60 filter Max pool\n",
    "     \n",
    "\n",
    "* Layer  5: Fully connected with dropout 240x500\n",
    "\n",
    "* Layer  6: Fully connected with dropout 500x250\n",
    "\n",
    "* Layer  7: Fully connected with dropout 250x125\n",
    "\n",
    "* Layer  8: Fully connected 125x43\n",
    "\n",
    "\n",
    "* Output  : Softmax layer put in loss function\n",
    "\n",
    "---\n",
    "\n",
    "Loss function includes l2 regularization on all weights in fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "# New net as described above. In addition to logits, returns the fully connected \n",
    "#  layer's weights for l2 penalty in loss function.  \n",
    "def new_net(x):    \n",
    "    #=============================================================================\n",
    "    # hyper params\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # added hyper parameter for dropout \n",
    "    keep_prob = 0.5\n",
    "    #=============================================================================\n",
    "\n",
    "    #=============================================================================\n",
    "    # conv Layer 1\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # pooling 1\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    #=============================================================================\n",
    "\n",
    "    #=============================================================================\n",
    "    # conv Layer 2\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 12), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(12))\n",
    "    conv2   = tf.nn.conv2d(conv1_pool, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    #=============================================================================\n",
    "    \n",
    "    #=============================================================================\n",
    "    # layer 3: try inception-like layer \n",
    "    incept1_W = tf.Variable(tf.truncated_normal(shape=(1, 1, 12, 12), mean = mu, stddev = sigma))\n",
    "    incept1_b = tf.Variable(tf.zeros(12))\n",
    "    incept1   = tf.nn.conv2d(conv2, incept1_W, strides=[1, 1, 1, 1], padding='SAME') + incept1_b\n",
    "    incept1 = tf.nn.relu(incept1)\n",
    "    \n",
    "    incept2_W = tf.Variable(tf.truncated_normal(shape=(1, 1, 12, 12), mean = mu, stddev = sigma))\n",
    "    incept2_b = tf.Variable(tf.zeros(12))\n",
    "    incept2   = tf.nn.conv2d(conv2, incept2_W, strides=[1, 1, 1, 1], padding='SAME') + incept2_b\n",
    "    incept2 = tf.nn.relu(incept2)\n",
    "    \n",
    "    incept3_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 12, 12), mean = mu, stddev = sigma))\n",
    "    incept3_b = tf.Variable(tf.zeros(12))\n",
    "    incept3   = tf.nn.conv2d(incept2, incept3_W, strides=[1, 1, 1, 1], padding='SAME') + incept3_b\n",
    "    incept3 = tf.nn.relu(incept3)\n",
    "    \n",
    "    incept4 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    incept5_W = tf.Variable(tf.truncated_normal(shape=(1, 1, 12, 12), mean = mu, stddev = sigma))\n",
    "    incept5_b = tf.Variable(tf.zeros(12))\n",
    "    incept5   = tf.nn.conv2d(incept4, incept5_W, strides=[1, 1, 1, 1], padding='SAME') + incept5_b\n",
    "    incept5 = tf.nn.relu(incept5)\n",
    "    \n",
    "    incept6_W = tf.Variable(tf.truncated_normal(shape=(1, 1, 12, 12), mean = mu, stddev = sigma))\n",
    "    incept6_b = tf.Variable(tf.zeros(12))\n",
    "    incept6   = tf.nn.conv2d(conv2, incept6_W, strides=[1, 1, 1, 1], padding='SAME') + incept6_b\n",
    "    incept6 = tf.nn.relu(incept6)\n",
    "    \n",
    "    incept7_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 12, 12), mean = mu, stddev = sigma))\n",
    "    incept7_b = tf.Variable(tf.zeros(12))\n",
    "    incept7   = tf.nn.conv2d(incept6, incept7_W, strides=[1, 1, 1, 1], padding='SAME') + incept7_b\n",
    "    incept7 = tf.nn.relu(incept7)\n",
    "    \n",
    "    concat_layer = tf.concat(3,[incept1, incept3, incept5, incept7])\n",
    "    concat_layer = tf.nn.relu(concat_layer)\n",
    "    #=============================================================================\n",
    "    \n",
    "    #=============================================================================\n",
    "    # layer 4: conv 2d\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(7, 7, 48, 60), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(60))\n",
    "    conv3   = tf.nn.conv2d(concat_layer, conv3_W, strides=[1, 1, 1, 1], padding='VALID') + conv3_b\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    \n",
    "    # pooling 2\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    #=============================================================================\n",
    "      \n",
    "    #=============================================================================\n",
    "    # flatten out for fc layer \n",
    "    fc0   = flatten(conv3_pool)\n",
    "    #=============================================================================\n",
    "    \n",
    "    #=============================================================================\n",
    "    # fully connected layers with dropout\n",
    "    # layer 5: fully connected with dropout, relu\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(240, 500), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(500))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    fc1    = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # Layer 6: Fully Connected with dropout, relu\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(500, 250), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(250))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    fc2    = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    # Layer 7: Fully Connected with dropout, relu\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(250, 125), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(125))\n",
    "    fc3    = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    fc3    = tf.nn.relu(fc3)\n",
    "    fc3    = tf.nn.dropout(fc3, keep_prob)\n",
    "\n",
    "    # Layer 8: Fully Connected relu\n",
    "    fc4_W  = tf.Variable(tf.truncated_normal(shape=(125, 43), mean = mu, stddev = sigma))\n",
    "    fc4_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc3, fc4_W) + fc4_b\n",
    "    #=============================================================================\n",
    "\n",
    "    # return logits before softmax and fc weights\n",
    "    return logits, fc1_W, fc2_W, fc3_W, fc4_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define remainder of model and training gradient\n",
    "* Define place holders\n",
    "* Define learning rate input to Adam optimizer \n",
    "* Define l2 loss constant (ended up being 0.01, rather high in my oppinion\n",
    "* Evaluation function, set to return accuracy, metric chosen from the lab material\n",
    "* Set epochs\n",
    "* Set batch size\n",
    "\n",
    "I tried a few different batch sizes, including a large one, though the 128 seemed to be the fastest. Through manual hyper parameter tuning, I found about 40 epochs and a l2 loss constant of 0.01 to get a pretty good score. Additinoally, I tuned the keep_prob rate definined in the new_net function to 0.5 through trial and error. Additionally adadelta was used as an alternative optimization scheme, though adam proved to be better. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================================================\n",
    "# Define placeholders \n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "#==========================================================================\n",
    "\n",
    "#==========================================================================\n",
    "# rate into Adam optimizer\n",
    "rate = 0.001 \n",
    "# hyper parameter: l2 loss constant, 1*10^-4 (my experience, kind of big.)\n",
    "loss_const = 0.01 #0.0000411\n",
    "#==========================================================================\n",
    "\n",
    "#==========================================================================\n",
    "# get outputs, calcualte loss and define training gradient\n",
    "logits, fc1_W, fc2_W, fc3_W, fc4_W = new_net(x)\n",
    "cross_entropy_l2 = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "\n",
    "# define this for predictins later\n",
    "preds = tf.placeholder(tf.float32, (None, 32))\n",
    "preds = tf.nn.softmax(logits)\n",
    "preds = tf.Print(preds, [preds])\n",
    "\n",
    "# calcualte the l2 loss penalty\n",
    "loss_penalty = loss_const*tf.nn.l2_loss(fc1_W) + loss_const*tf.nn.l2_loss(fc2_W)\\\n",
    "+ loss_const*tf.nn.l2_loss(fc3_W) + loss_const*tf.nn.l2_loss(fc4_W)\n",
    "\n",
    "# feed it into the mean \n",
    "loss_operation = tf.reduce_mean(cross_entropy_l2 + loss_penalty)\n",
    "\n",
    "# keep adam as optimizer for now\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "\n",
    "# run minimize \n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "#=========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate the loss and accuracy of the trained model for a given dataset. The following code is from the class material. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================================\n",
    "# define the performance operations \n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "#============================================================================\n",
    "\n",
    "#============================================================================\n",
    "# evaluate the model from the default session and input X and y. \n",
    "# use this equation for testing and on non-training data\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "#============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model. This function from the class material. \n",
    "\n",
    "Brief summary:\n",
    "\n",
    "* Before each epoch, shuffles the training set.\n",
    "\n",
    "* After each epoch, measures the loss and accuracy of the validation set.\n",
    "\n",
    "* prints out training and validation metrics at each epoch\n",
    "\n",
    "* Saves the model after training\n",
    "___\n",
    "The result, ~98% accuracy on train, ~97% accuracy on validation suggest that the model is not overfit, though, its worth exploring further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "epoch,train_acc,valid_acc\n",
      "1,0.409,0.409\n",
      "2,0.618,0.614\n",
      "3,0.772,0.767\n",
      "4,0.835,0.831\n",
      "5,0.856,0.849\n",
      "6,0.885,0.877\n",
      "7,0.902,0.892\n",
      "8,0.913,0.902\n",
      "9,0.915,0.905\n",
      "10,0.921,0.911\n",
      "11,0.930,0.922\n",
      "12,0.946,0.935\n",
      "13,0.933,0.925\n",
      "14,0.959,0.947\n",
      "15,0.947,0.939\n",
      "16,0.949,0.943\n",
      "17,0.954,0.943\n",
      "18,0.955,0.947\n",
      "19,0.967,0.958\n",
      "20,0.971,0.960\n",
      "21,0.967,0.960\n",
      "22,0.966,0.958\n",
      "23,0.964,0.955\n",
      "24,0.958,0.948\n",
      "25,0.969,0.959\n",
      "26,0.967,0.958\n",
      "27,0.968,0.961\n",
      "28,0.975,0.966\n",
      "29,0.974,0.965\n",
      "30,0.968,0.956\n",
      "31,0.973,0.964\n",
      "32,0.978,0.968\n",
      "33,0.971,0.963\n",
      "34,0.977,0.968\n",
      "35,0.966,0.958\n",
      "36,0.974,0.964\n",
      "37,0.974,0.966\n",
      "38,0.975,0.966\n",
      "39,0.975,0.966\n",
      "40,0.979,0.972\n",
      "41,0.981,0.971\n",
      "42,0.980,0.972\n",
      "43,0.977,0.967\n",
      "44,0.974,0.964\n",
      "45,0.982,0.971\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "#============================================================================\n",
    "# Train the model on X_train and y_train from the data_prep function\n",
    "EPOCHS = 45\n",
    "# small batch size seems to run faster\n",
    "BATCH_SIZE = 128\n",
    "#============================================================================\n",
    "\n",
    "#============================================================================\n",
    "# Tensor flow session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    print(\"epoch,train_acc,valid_acc\")\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "           \n",
    "        training_accuracy = evaluate(X_train, y_train)\n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        # edited for easy copy-paste to visualize training history \n",
    "        print(\"{}\".format(i+1) + \",{:.3f}\".format(training_accuracy) + \",{:.3f}\".format(validation_accuracy)) \n",
    "    saver.save(sess, './train_45')\n",
    "    print()\n",
    "    print(\"Model saved\")\n",
    "#============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Further Exploration\n",
    "In addition to extra traffic signs, I ran a few very realistic \"out-of-sample\" pictures:\n",
    "\n",
    "* A traffic sign not included in the training data:\n",
    "\n",
    "* Something strange on the roadside:\n",
    "\n",
    "* A photograph of a person:\n",
    "\n",
    "![](pics/big_five.png)\n",
    "\n",
    "\n",
    "* A random instagram picture:\n",
    "\n",
    "<img src = \"./pics/blue_big.png\">\n",
    "\n",
    "\n",
    "* And, in honor of the 46th annaversay of the Willy Wonka and the Cholocate Factory film, like a misbehaving candy-wonderland visitor, I go through the classifier myself: \n",
    "\n",
    "<img src = \"./pics/me_big.jpg\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "___\n",
    "## Why do this? \n",
    "I know this is outside the use case of a supervised classifier, but thats the point im making. One reason the model performs with the metrics it does is we are feeding it a nice test set, or a data set with only expected examples. In surpervised classification, we have to do this in training, as we are forced to have a label for every example. Although this is powerful and replaces a clumsy, complicated \"by-hand\" logic engine, it has limiations. The problem I'm talking about is when the model is feed an image and outputs a strong classification probability which is completely outragous. As far as this model knows, the whole world is made up of 43 traffic signs with strange unknown patterns behind them. No matter what you show it, there is only 43 things it could be. \n",
    "\n",
    "Imagine this classifier actually employed in a self driving car rolling down the road. Maybe its connected to a wide angle camera or whatever, classifing its little robot heart out. Is it likely it will *never* make a serious mistake? Very doubtful. Granted, it will probably not see childish drawings made with paint or a zoomed-in selfie, but a piece of trash leaned up against a tree? An oversized bird eating roadkill with the sun reflecting off it just right? If it ends up being fed an image like this, it might have a dangerous result. \n",
    "\n",
    "The model has an incredible ability to decompose images looking for little odds and ends that together can identify whole objects, but has no over-arching contextual knowldege of the problem. Thus, it is vulnerable to rediculus outcomes and we would have to contextually baby-sit the model in implementation by showing it only nice pictures of nice things that fit into its limited world view. \n",
    "\n",
    "Training models to classify images in this way is truly amazing, however, it is important to remember that actually implemenating any model is messy, filled with unexpected problems. Launching is a maddening, weakness-highlgtling, surprising test of your whole design, which a neural network will only be a part of. There is little room for error in a self drving car application. \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAADbCAYAAACLF+9EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngACP/w9uQk8zRSuyZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a9461b518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#===================================================================\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "#===================================================================\n",
    "\n",
    "#===================================================================\n",
    "# change working directory\n",
    "os.chdir(\"/home/andy/Desktop/udacity-p2/try2/CarND-LeNet-Lab/pics/small/\")\n",
    "# file names of the exra pics\n",
    "images = os.listdir()\n",
    "me = images[1]\n",
    "del images[1]\n",
    "\n",
    "#===================================================================\n",
    "#read them in \n",
    "extra_images = []\n",
    "for img in images:\n",
    "    read_in = (mpimg.imread(img))\n",
    "    # slice off the alpha channel \n",
    "    slice_in = read_in[:,:,0:3]\n",
    "    extra_images.append(slice_in)\n",
    "    \n",
    "\n",
    "\n",
    "extra_images.append(mpimg.imread(me))\n",
    "    \n",
    "look = np.stack(extra_images, axis = 0)\n",
    "#===================================================================\n",
    "\n",
    "#===================================================================\n",
    "# make the data like X_train \n",
    "#X_wild, y_empty, plot_pics = data_prep(X = look_slice[0:3], y = None, vis_num = 2)\n",
    "X_wild = look / 255\n",
    "#===================================================================\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# plot seected examples from original and rotated sets\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, image in  enumerate(look):\n",
    "    plt.subplot(2,3,1+i)\n",
    "    plt.imshow(image)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/home/andy/Desktop/udacity-p2/try2/CarND-LeNet-Lab/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.19172763e-02   1.64923463e-02   1.44181177e-02   8.00658315e-02\n",
      "    6.42922847e-03   1.95021126e-02   3.73653807e-02   2.08626594e-03\n",
      "    4.92455298e-03   2.44193734e-03   4.00648639e-03   4.58267443e-02\n",
      "    2.53271451e-03   1.49891684e-02   6.28642598e-03   6.10885443e-03\n",
      "    3.74535751e-03   6.49150112e-04   2.28117973e-01   3.41135114e-02\n",
      "    8.45934264e-03   2.99833398e-02   2.66006775e-03   7.15801073e-03\n",
      "    5.41747212e-02   6.18853746e-03   8.79432037e-02   4.48120460e-02\n",
      "    8.45069904e-03   1.00513563e-01   2.72771679e-02   1.97466258e-02\n",
      "    1.16970809e-02   1.33135617e-02   4.31298790e-03   4.40977921e-04\n",
      "    3.95384477e-03   4.10214439e-03   9.12075513e-04   6.87678391e-03\n",
      "    5.85601525e-03   2.32052733e-03   6.82725059e-03]\n",
      " [  2.30902131e-03   2.47794832e-03   2.72494392e-03   1.37878865e-01\n",
      "    1.92490383e-03   1.19033093e-02   2.55383309e-02   1.07633776e-03\n",
      "    7.99743552e-03   2.26442004e-03   2.03257729e-03   1.16715981e-02\n",
      "    1.06293708e-03   1.70780346e-02   8.52975901e-03   1.09464601e-02\n",
      "    3.13494541e-03   2.76034442e-03   3.43641490e-01   1.18375514e-02\n",
      "    6.26069540e-03   9.05878190e-03   5.78079186e-03   3.94843007e-03\n",
      "    1.35560473e-02   9.08338930e-04   2.78968383e-02   4.97718481e-03\n",
      "    3.19794305e-02   2.11568087e-01   1.13688316e-02   4.86257207e-03\n",
      "    1.58542190e-02   2.60384250e-02   2.44485307e-03   2.12802115e-04\n",
      "    3.32200644e-03   1.67512940e-03   3.44263855e-04   3.70421680e-03\n",
      "    1.42744114e-03   1.15238596e-03   2.86698388e-03]\n",
      " [  1.64810673e-03   7.09342677e-03   4.51106485e-03   1.16591370e-02\n",
      "    1.81128795e-03   1.04861346e-03   4.35257936e-03   3.50277289e-04\n",
      "    2.29439070e-03   3.09199560e-03   5.33005688e-04   1.05763841e-02\n",
      "    3.58889392e-03   1.22428387e-02   3.51421791e-03   1.59541816e-02\n",
      "    3.13084573e-04   4.81679570e-04   7.75563121e-01   1.56551925e-03\n",
      "    2.77111446e-03   9.04842396e-04   1.06236176e-03   2.32253355e-04\n",
      "    4.84706322e-03   1.03372522e-03   3.76167223e-02   1.03101917e-02\n",
      "    7.26474542e-03   1.73773691e-02   3.49798426e-03   4.76510235e-04\n",
      "    1.64692774e-02   1.97569933e-02   1.95971248e-03   2.94644793e-04\n",
      "    1.18536165e-03   1.17727718e-03   1.63125704e-04   3.59112979e-03\n",
      "    1.61986973e-03   2.95046205e-03   1.24337315e-03]\n",
      " [  2.96267904e-02   7.55061135e-02   2.41919942e-02   1.96538847e-02\n",
      "    1.87476408e-02   1.06064854e-02   3.02009974e-02   2.59395596e-03\n",
      "    2.05963179e-02   8.56954791e-03   8.08579288e-03   1.55075500e-02\n",
      "    2.64988281e-02   1.39007922e-02   1.86561432e-03   1.31713673e-02\n",
      "    2.01797881e-03   1.01720612e-03   1.74138680e-01   1.24132354e-02\n",
      "    3.31320129e-02   1.10273194e-02   2.58519733e-03   4.02468722e-03\n",
      "    2.81127077e-02   1.05162123e-02   2.01474071e-01   5.84962666e-02\n",
      "    5.12997760e-03   1.03151174e-02   8.45053792e-03   6.33803615e-03\n",
      "    1.89226940e-02   1.58227440e-02   1.00750392e-02   7.05714396e-04\n",
      "    1.16777234e-02   8.00479855e-03   1.43374247e-03   1.16274664e-02\n",
      "    1.19840605e-02   6.91980729e-03   1.43133523e-02]\n",
      " [  1.27823069e-03   1.89029728e-03   4.73678904e-03   1.78202078e-01\n",
      "    1.70618499e-04   2.98095378e-03   1.30717484e-02   3.40947969e-04\n",
      "    3.90984723e-03   2.59494223e-03   5.09392645e-04   5.62809221e-03\n",
      "    2.02917517e-03   6.47959951e-03   1.06225777e-02   2.65302751e-02\n",
      "    7.03080208e-04   1.53481262e-03   4.84380841e-01   3.17883492e-03\n",
      "    6.71412796e-04   1.72599091e-03   5.25819464e-03   5.86632290e-04\n",
      "    1.82922417e-03   4.12409398e-04   1.10375956e-02   2.85939267e-03\n",
      "    9.64963622e-03   5.11343889e-02   1.01989205e-03   1.91321631e-03\n",
      "    6.33600131e-02   8.58445540e-02   9.67331114e-04   2.29812766e-04\n",
      "    9.79733886e-04   7.94565072e-04   3.46177287e-04   2.93597160e-03\n",
      "    2.00018706e-03   2.65585911e-03   1.01471518e-03]\n",
      " [  2.73041474e-03   3.93294310e-03   1.67100574e-03   4.55508009e-02\n",
      "    3.82681290e-04   1.87217770e-03   2.50831470e-02   1.58575000e-04\n",
      "    8.71851516e-04   6.77021046e-04   2.42955124e-04   7.28291180e-03\n",
      "    9.01976600e-04   5.70324529e-03   4.12030751e-03   3.93249281e-03\n",
      "    4.75947134e-04   4.30962333e-04   7.24410355e-01   2.49036122e-03\n",
      "    1.76157837e-03   2.22058315e-03   2.99608987e-03   8.58381391e-04\n",
      "    8.75899009e-03   1.13886909e-03   9.48797446e-03   1.07412096e-02\n",
      "    9.36705898e-03   5.46530895e-02   2.38124211e-03   2.17652041e-03\n",
      "    4.52950597e-02   8.06270167e-03   1.01335521e-03   9.06705318e-05\n",
      "    1.54436764e-03   3.90639703e-04   1.78708418e-04   3.73869610e-04\n",
      "    7.17531249e-04   1.59485510e-03   1.27453357e-03]] [18 18 18 26 18 18]\n"
     ]
    }
   ],
   "source": [
    "#============================================================================\n",
    "# run X_wild through the model to see what the pics are: \n",
    "\n",
    "# change working directory back\n",
    "#os.chdir(\"/home/andy/Desktop/udacity-p2/try2/CarND-LeNet-Lab/\")\n",
    "\n",
    "# no batching nessesary\n",
    "# make a quick predict function:\n",
    "#def predict(x):\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "#prediction = tf.Print(prediction, [prediction])\n",
    "#    return y\n",
    "#init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\".\"))\n",
    "    #sess.run(init)\n",
    "    get = sess.run(preds, feed_dict={x: X_wild})\n",
    "    choose = tf.argmax(get, 1) \n",
    "    print(get, choose.eval())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Post-training an evalutation, I tested the model on a decent amount of hold-out data for a \"one-and-done\" number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.469\n"
     ]
    }
   ],
   "source": [
    "# redefine batch sze (if loading from saved)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\".\"))\n",
    "    test_accuracy = evaluate(X_test_process, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.45490196,  0.54509804,  0.68235294],\n",
       "         [ 0.45490196,  0.5372549 ,  0.67058824],\n",
       "         [ 0.4627451 ,  0.54117647,  0.6745098 ],\n",
       "         ..., \n",
       "         [ 0.38431373,  0.44705882,  0.56078431],\n",
       "         [ 0.38039216,  0.4745098 ,  0.57647059],\n",
       "         [ 0.33333333,  0.41176471,  0.50980392]],\n",
       "\n",
       "        [[ 0.45098039,  0.55686275,  0.69019608],\n",
       "         [ 0.45098039,  0.54901961,  0.68235294],\n",
       "         [ 0.45882353,  0.55294118,  0.68627451],\n",
       "         ..., \n",
       "         [ 0.46666667,  0.56078431,  0.69019608],\n",
       "         [ 0.47058824,  0.55294118,  0.67843137],\n",
       "         [ 0.47058824,  0.54509804,  0.67058824]],\n",
       "\n",
       "        [[ 0.45882353,  0.55294118,  0.68235294],\n",
       "         [ 0.45882353,  0.55686275,  0.68627451],\n",
       "         [ 0.44705882,  0.54901961,  0.6745098 ],\n",
       "         ..., \n",
       "         [ 0.47058824,  0.56470588,  0.70196078],\n",
       "         [ 0.47843137,  0.56470588,  0.70196078],\n",
       "         [ 0.47058824,  0.56078431,  0.69411765]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.45882353,  0.5372549 ,  0.65490196],\n",
       "         [ 0.45098039,  0.5254902 ,  0.64313725],\n",
       "         [ 0.45882353,  0.52941176,  0.64313725],\n",
       "         ..., \n",
       "         [ 0.45098039,  0.5372549 ,  0.6627451 ],\n",
       "         [ 0.45490196,  0.53333333,  0.65882353],\n",
       "         [ 0.4627451 ,  0.54509804,  0.6745098 ]],\n",
       "\n",
       "        [[ 0.45490196,  0.53333333,  0.65098039],\n",
       "         [ 0.44705882,  0.5254902 ,  0.65882353],\n",
       "         [ 0.44313725,  0.51372549,  0.65098039],\n",
       "         ..., \n",
       "         [ 0.44313725,  0.52941176,  0.65490196],\n",
       "         [ 0.45882353,  0.53333333,  0.64705882],\n",
       "         [ 0.45098039,  0.54509804,  0.65490196]],\n",
       "\n",
       "        [[ 0.43921569,  0.52941176,  0.65490196],\n",
       "         [ 0.43137255,  0.5254902 ,  0.64705882],\n",
       "         [ 0.46666667,  0.52941176,  0.64705882],\n",
       "         ..., \n",
       "         [ 0.45098039,  0.54117647,  0.65490196],\n",
       "         [ 0.45882353,  0.54117647,  0.65490196],\n",
       "         [ 0.44705882,  0.54901961,  0.66666667]]],\n",
       "\n",
       "\n",
       "       [[[ 0.23137255,  0.2745098 ,  0.23921569],\n",
       "         [ 0.34117647,  0.31372549,  0.24705882],\n",
       "         [ 0.36078431,  0.31764706,  0.24705882],\n",
       "         ..., \n",
       "         [ 0.30196078,  0.25098039,  0.2627451 ],\n",
       "         [ 0.27843137,  0.25490196,  0.2627451 ],\n",
       "         [ 0.29019608,  0.27058824,  0.26666667]],\n",
       "\n",
       "        [[ 0.23137255,  0.26666667,  0.22745098],\n",
       "         [ 0.36862745,  0.3254902 ,  0.25490196],\n",
       "         [ 0.37254902,  0.31372549,  0.24313725],\n",
       "         ..., \n",
       "         [ 0.30196078,  0.25098039,  0.25882353],\n",
       "         [ 0.36078431,  0.27058824,  0.2745098 ],\n",
       "         [ 0.33333333,  0.26666667,  0.26666667]],\n",
       "\n",
       "        [[ 0.21960784,  0.26666667,  0.22745098],\n",
       "         [ 0.35294118,  0.32941176,  0.2627451 ],\n",
       "         [ 0.37254902,  0.32156863,  0.25098039],\n",
       "         ..., \n",
       "         [ 0.28235294,  0.25490196,  0.25882353],\n",
       "         [ 0.31372549,  0.2627451 ,  0.27058824],\n",
       "         [ 0.30980392,  0.27058824,  0.2745098 ]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.18823529,  0.18431373,  0.16862745],\n",
       "         [ 0.30980392,  0.26666667,  0.22352941],\n",
       "         [ 0.31372549,  0.25882353,  0.21960784],\n",
       "         ..., \n",
       "         [ 0.26666667,  0.24705882,  0.24705882],\n",
       "         [ 0.30588235,  0.25490196,  0.25490196],\n",
       "         [ 0.29803922,  0.25882353,  0.26666667]],\n",
       "\n",
       "        [[ 0.19215686,  0.18039216,  0.17647059],\n",
       "         [ 0.30588235,  0.25882353,  0.23921569],\n",
       "         [ 0.30588235,  0.25490196,  0.22745098],\n",
       "         ..., \n",
       "         [ 0.23529412,  0.23529412,  0.23921569],\n",
       "         [ 0.26666667,  0.25490196,  0.25490196],\n",
       "         [ 0.28627451,  0.2627451 ,  0.2627451 ]],\n",
       "\n",
       "        [[ 0.2       ,  0.17647059,  0.17647059],\n",
       "         [ 0.30588235,  0.25882353,  0.23921569],\n",
       "         [ 0.30980392,  0.25882353,  0.22745098],\n",
       "         ..., \n",
       "         [ 0.24313725,  0.23137255,  0.24313725],\n",
       "         [ 0.28627451,  0.2627451 ,  0.2745098 ],\n",
       "         [ 0.29411765,  0.2745098 ,  0.2745098 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.20392157,  0.15686275,  0.14901961],\n",
       "         [ 0.2       ,  0.15294118,  0.14509804],\n",
       "         [ 0.19607843,  0.14901961,  0.14509804],\n",
       "         ..., \n",
       "         [ 0.20784314,  0.17254902,  0.18039216],\n",
       "         [ 0.21176471,  0.17647059,  0.18823529],\n",
       "         [ 0.21568627,  0.17647059,  0.18823529]],\n",
       "\n",
       "        [[ 0.23137255,  0.17647059,  0.16470588],\n",
       "         [ 0.23137255,  0.17254902,  0.16078431],\n",
       "         [ 0.21960784,  0.17254902,  0.15686275],\n",
       "         ..., \n",
       "         [ 0.20392157,  0.16078431,  0.16470588],\n",
       "         [ 0.21176471,  0.17254902,  0.17647059],\n",
       "         [ 0.21568627,  0.18039216,  0.17647059]],\n",
       "\n",
       "        [[ 0.2627451 ,  0.19215686,  0.17254902],\n",
       "         [ 0.25490196,  0.19607843,  0.17647059],\n",
       "         [ 0.25490196,  0.19215686,  0.17647059],\n",
       "         ..., \n",
       "         [ 0.22352941,  0.16470588,  0.15294118],\n",
       "         [ 0.21568627,  0.16470588,  0.15686275],\n",
       "         [ 0.21960784,  0.16862745,  0.15686275]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.10980392,  0.09411765,  0.10196078],\n",
       "         [ 0.11372549,  0.09803922,  0.10588235],\n",
       "         [ 0.11372549,  0.10588235,  0.11764706],\n",
       "         ..., \n",
       "         [ 0.10588235,  0.09411765,  0.09411765],\n",
       "         [ 0.10980392,  0.09803922,  0.09411765],\n",
       "         [ 0.11372549,  0.10588235,  0.10588235]],\n",
       "\n",
       "        [[ 0.12156863,  0.10980392,  0.11372549],\n",
       "         [ 0.14509804,  0.1254902 ,  0.13333333],\n",
       "         [ 0.16078431,  0.1372549 ,  0.14509804],\n",
       "         ..., \n",
       "         [ 0.13333333,  0.12156863,  0.10980392],\n",
       "         [ 0.16470588,  0.15686275,  0.14901961],\n",
       "         [ 0.18431373,  0.17647059,  0.17647059]],\n",
       "\n",
       "        [[ 0.1254902 ,  0.11372549,  0.11764706],\n",
       "         [ 0.12941176,  0.10980392,  0.10980392],\n",
       "         [ 0.17254902,  0.13333333,  0.1254902 ],\n",
       "         ..., \n",
       "         [ 0.16078431,  0.15686275,  0.14901961],\n",
       "         [ 0.17254902,  0.16862745,  0.16862745],\n",
       "         [ 0.18431373,  0.18039216,  0.17254902]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.09411765,  0.10588235,  0.13333333],\n",
       "         [ 0.09019608,  0.09803922,  0.1254902 ],\n",
       "         [ 0.09411765,  0.09803922,  0.1254902 ],\n",
       "         ..., \n",
       "         [ 0.10196078,  0.10588235,  0.12941176],\n",
       "         [ 0.10196078,  0.10588235,  0.13333333],\n",
       "         [ 0.10196078,  0.10588235,  0.13333333]],\n",
       "\n",
       "        [[ 0.09803922,  0.10196078,  0.12941176],\n",
       "         [ 0.09803922,  0.10196078,  0.13333333],\n",
       "         [ 0.09803922,  0.10196078,  0.12941176],\n",
       "         ..., \n",
       "         [ 0.10196078,  0.10588235,  0.13333333],\n",
       "         [ 0.10588235,  0.10588235,  0.1372549 ],\n",
       "         [ 0.10980392,  0.10980392,  0.14117647]],\n",
       "\n",
       "        [[ 0.10196078,  0.10196078,  0.1254902 ],\n",
       "         [ 0.09803922,  0.09803922,  0.1254902 ],\n",
       "         [ 0.09803922,  0.09803922,  0.12156863],\n",
       "         ..., \n",
       "         [ 0.10196078,  0.10588235,  0.12941176],\n",
       "         [ 0.10588235,  0.10588235,  0.12941176],\n",
       "         [ 0.10588235,  0.10196078,  0.13333333]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.0627451 ,  0.06666667,  0.08235294],\n",
       "         [ 0.05882353,  0.0627451 ,  0.08235294],\n",
       "         [ 0.05490196,  0.0627451 ,  0.08235294],\n",
       "         ..., \n",
       "         [ 0.0745098 ,  0.08235294,  0.11764706],\n",
       "         [ 0.07843137,  0.08627451,  0.1254902 ],\n",
       "         [ 0.0745098 ,  0.08235294,  0.11764706]],\n",
       "\n",
       "        [[ 0.0627451 ,  0.06666667,  0.08627451],\n",
       "         [ 0.05882353,  0.0627451 ,  0.08235294],\n",
       "         [ 0.05490196,  0.0627451 ,  0.08235294],\n",
       "         ..., \n",
       "         [ 0.0745098 ,  0.08235294,  0.11764706],\n",
       "         [ 0.07843137,  0.08627451,  0.1254902 ],\n",
       "         [ 0.0745098 ,  0.08627451,  0.1254902 ]],\n",
       "\n",
       "        [[ 0.05882353,  0.0627451 ,  0.08235294],\n",
       "         [ 0.05882353,  0.0627451 ,  0.08235294],\n",
       "         [ 0.05490196,  0.0627451 ,  0.08235294],\n",
       "         ..., \n",
       "         [ 0.07058824,  0.08235294,  0.11764706],\n",
       "         [ 0.0745098 ,  0.08627451,  0.1254902 ],\n",
       "         [ 0.07058824,  0.08627451,  0.12156863]]],\n",
       "\n",
       "\n",
       "       [[[ 0.18431373,  0.22745098,  0.28627451],\n",
       "         [ 0.19215686,  0.20784314,  0.2627451 ],\n",
       "         [ 0.23137255,  0.22352941,  0.24705882],\n",
       "         ..., \n",
       "         [ 0.15294118,  0.14117647,  0.17254902],\n",
       "         [ 0.04705882,  0.03921569,  0.04705882],\n",
       "         [ 0.03921569,  0.03529412,  0.04705882]],\n",
       "\n",
       "        [[ 0.23921569,  0.26666667,  0.32941176],\n",
       "         [ 0.23921569,  0.22745098,  0.28235294],\n",
       "         [ 0.23529412,  0.22352941,  0.2627451 ],\n",
       "         ..., \n",
       "         [ 0.10196078,  0.09019608,  0.12156863],\n",
       "         [ 0.04705882,  0.03921569,  0.03137255],\n",
       "         [ 0.04313725,  0.03529412,  0.04313725]],\n",
       "\n",
       "        [[ 0.25882353,  0.29411765,  0.36470588],\n",
       "         [ 0.28235294,  0.30980392,  0.38823529],\n",
       "         [ 0.2627451 ,  0.28627451,  0.36862745],\n",
       "         ..., \n",
       "         [ 0.14117647,  0.14117647,  0.14901961],\n",
       "         [ 0.09803922,  0.08235294,  0.05490196],\n",
       "         [ 0.05098039,  0.03529412,  0.03921569]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.0627451 ,  0.0627451 ,  0.0745098 ],\n",
       "         [ 0.05882353,  0.05882353,  0.07058824],\n",
       "         [ 0.05490196,  0.05098039,  0.06666667],\n",
       "         ..., \n",
       "         [ 0.1254902 ,  0.12156863,  0.14509804],\n",
       "         [ 0.14117647,  0.14509804,  0.17254902],\n",
       "         [ 0.09411765,  0.09411765,  0.09019608]],\n",
       "\n",
       "        [[ 0.05098039,  0.04705882,  0.05882353],\n",
       "         [ 0.05098039,  0.04705882,  0.05490196],\n",
       "         [ 0.04705882,  0.04313725,  0.05098039],\n",
       "         ..., \n",
       "         [ 0.10196078,  0.10980392,  0.12941176],\n",
       "         [ 0.1254902 ,  0.1372549 ,  0.15294118],\n",
       "         [ 0.10980392,  0.10588235,  0.09411765]],\n",
       "\n",
       "        [[ 0.04705882,  0.04313725,  0.05490196],\n",
       "         [ 0.04705882,  0.04313725,  0.05490196],\n",
       "         [ 0.04705882,  0.03921569,  0.04705882],\n",
       "         ..., \n",
       "         [ 0.10980392,  0.1254902 ,  0.15686275],\n",
       "         [ 0.14117647,  0.14509804,  0.15686275],\n",
       "         [ 0.11372549,  0.10588235,  0.08627451]]],\n",
       "\n",
       "\n",
       "       [[[ 0.03921569,  0.03921569,  0.05098039],\n",
       "         [ 0.03921569,  0.03921569,  0.05098039],\n",
       "         [ 0.03921569,  0.03529412,  0.04705882],\n",
       "         ..., \n",
       "         [ 0.05098039,  0.04705882,  0.05882353],\n",
       "         [ 0.05098039,  0.04705882,  0.05882353],\n",
       "         [ 0.05098039,  0.04705882,  0.0627451 ]],\n",
       "\n",
       "        [[ 0.04705882,  0.04313725,  0.05490196],\n",
       "         [ 0.03529412,  0.03529412,  0.04705882],\n",
       "         [ 0.03529412,  0.03529412,  0.04705882],\n",
       "         ..., \n",
       "         [ 0.05098039,  0.04705882,  0.05490196],\n",
       "         [ 0.05098039,  0.04705882,  0.05882353],\n",
       "         [ 0.05098039,  0.04705882,  0.0627451 ]],\n",
       "\n",
       "        [[ 0.04313725,  0.03529412,  0.04313725],\n",
       "         [ 0.03529412,  0.03137255,  0.04313725],\n",
       "         [ 0.03529412,  0.03529412,  0.04705882],\n",
       "         ..., \n",
       "         [ 0.05098039,  0.04705882,  0.05490196],\n",
       "         [ 0.05098039,  0.04705882,  0.05882353],\n",
       "         [ 0.05098039,  0.04705882,  0.0627451 ]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.04313725,  0.03529412,  0.05098039],\n",
       "         [ 0.03921569,  0.03529412,  0.04705882],\n",
       "         [ 0.04313725,  0.03921569,  0.05098039],\n",
       "         ..., \n",
       "         [ 0.04313725,  0.03921569,  0.05098039],\n",
       "         [ 0.03921569,  0.03529412,  0.04705882],\n",
       "         [ 0.04705882,  0.04313725,  0.05490196]],\n",
       "\n",
       "        [[ 0.04313725,  0.03921569,  0.05490196],\n",
       "         [ 0.04313725,  0.03921569,  0.05490196],\n",
       "         [ 0.04313725,  0.03921569,  0.05490196],\n",
       "         ..., \n",
       "         [ 0.03529412,  0.03529412,  0.04705882],\n",
       "         [ 0.03529412,  0.03529412,  0.04313725],\n",
       "         [ 0.04705882,  0.04313725,  0.05098039]],\n",
       "\n",
       "        [[ 0.03921569,  0.03921569,  0.05098039],\n",
       "         [ 0.03921569,  0.03529412,  0.04705882],\n",
       "         [ 0.04313725,  0.03529412,  0.04705882],\n",
       "         ..., \n",
       "         [ 0.03921569,  0.03921569,  0.05098039],\n",
       "         [ 0.03529412,  0.03921569,  0.04705882],\n",
       "         [ 0.04313725,  0.04313725,  0.05098039]]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
